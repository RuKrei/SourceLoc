{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Source localization pipeline - Stage2\n",
    "- coregistration\n",
    "- source localization\n",
    "- report generation\n",
    " \n",
    " \n",
    "\n",
    "\n",
    "#### Author\n",
    "Rudi Kreidenhuber <Rudi.Kreidenhuber@gmail.com>\n",
    "#### License\n",
    "BSD (3-clause)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Overall config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import mne\n",
    "from mne_bids import BIDSPath, write_raw_bids, read_raw_bids\n",
    "from src import Folderer, Anatomist, Reporter, SubjectDropDowner\n",
    "from src import Utils as u\n",
    "import pickle\n",
    "import pyvista\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# configuration\n",
    "input_dir = \"/home/meg/Schreibtisch/new_patients/processed\"\n",
    "bids_root = \"/run/media/meg/DATA/MEG/BIDS_clinic\"\n",
    "n_jobs = openmp = 30\n",
    "extras_directory = os.path.join(input_dir, \"..\", \"extras\")\n",
    "FS_SUBJECTS_DIR = \"/usr/local/freesurfer/subjects/\"\n",
    "spacing = \"ico4\"\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for dir in [input_dir, bids_root, extras_directory, FS_SUBJECTS_DIR]:\n",
    "    print(f\"{dir}\")\n",
    "\n",
    "\n",
    "def get_subject_list(input_dir = input_dir) -> list:\n",
    "    fiflist = [os.path.basename(f) for f in glob.glob(os.path.join(input_dir, \"*.fif\"))]\n",
    "    fiflist = [f.split(\"_\")[0] for f in fiflist]\n",
    "    print(fiflist)\n",
    "    return fiflist\n",
    "\n",
    "subjectlist = get_subject_list()\n",
    "\n",
    "dl = SubjectDropDowner.SubjectDropDowner(subjectlist)\n",
    "drop_menu = dl.create_subject_dropdown_widget()\n",
    "print(f\"\\n\\nChoose patient/ subject to process further:\")\n",
    "drop_menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = dl.get_subject_dropdown().value\n",
    "\n",
    "\n",
    "\n",
    "# delete me later\n",
    "subject = \"sub-FT05042011\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if not subject.startswith(\"sub-\"):\n",
    "    ject = subject\n",
    "    subject = \"sub-\" + subject\n",
    "else:\n",
    "    ject = subject.strip(\"sub-\")\n",
    "\n",
    "print(f\"Chosen Subject: {subject}\")\n",
    "\n",
    "# create output folders\n",
    "dfc = Folderer.DerivativesFoldersCreator(BIDS_root=bids_root, \n",
    "                                            extras_directory=extras_directory, \n",
    "                                            subject=subject)\n",
    "dfc.make_derivatives_folders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy freesurfer files to local subjects_dir\n",
    "try:\n",
    "    segmentation = os.path.join(os.path.abspath(FS_SUBJECTS_DIR), subject)\n",
    "    target = os.path.join(dfc.fanat, subject)\n",
    "    if not os.path.isdir(target):\n",
    "        os.mkdir(target)\n",
    "    dfc._recursive_overwrite(segmentation, target)\n",
    "except Exception as e:\n",
    "    print(f\"Couldn't copy freesurfer segmentation\\n--> {e}.\")\n",
    "    \n",
    "# create source models\n",
    "sourcerer = Anatomist.SourceModeler(subjects_dir=dfc.fanat, subject=subject, spacing=spacing, n_jobs=n_jobs)\n",
    "sourcerer.calculate_source_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Coregistration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfile = os.path.join(dfc.ftrans, subject + \"-trans.fif\")\n",
    "print(\"Starting coregistration...\")\n",
    "if os.path.isfile(transfile):\n",
    "    print(f\"Skipping coregistration, because a transfile ({transfile}) already exists\")\n",
    "else:\n",
    "    print(f\"\\n\\n\\n--> Transfile should be called: {transfile}\\n\\n\\n\")\n",
    "    try:\n",
    "        rawfile = os.path.join(input_dir, subject + \"_prepped.fif\")\n",
    "        mne.gui.coregistration(subject=subject, subjects_dir=dfc.fanat, inst=rawfile, block=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed launching Coregistration: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# .fif - File processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## load data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfile = os.path.join(input_dir, subject + \"_prepped.fif\")\n",
    "if not os.path.isfile(rawfile):\n",
    "    raw = mne.io.read_raw(rawfile, preload=False, on_split_missing=\"ignore\").load_data()\n",
    "else:\n",
    "    raw = mne.io.read_raw(rawfile)\n",
    "raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.info[\"projs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.get_data().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## merge events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_eventfile(event_file):\n",
    "    \"\"\"\n",
    "    Receives a .csv or .txt files as exported i.e. via brainstorm and\n",
    "    transforms it according to mne-needs.\n",
    "\n",
    "    Returns a tuple:\n",
    "    new_eve_file, event_dict\n",
    "    --> = transformed event-file, dictionary with Eventnames\n",
    "    \"\"\"\n",
    "\n",
    "    eve = pd.read_csv(event_file, header=0)\n",
    "    le = LabelEncoder()\n",
    "    labels = eve.iloc[:,0]\n",
    "    print(f\"Labels --> {labels}\")\n",
    "    l_enc = le.fit_transform(labels)\n",
    "    l_enc = l_enc\n",
    "    new_eve_file = pd.DataFrame([eve.iloc[:,1], eve.iloc[:,0], (l_enc +1)]).T\n",
    "    new_eve_file.reset_index(drop=True, inplace = True)\n",
    "    new_eve_file.iloc[:,0] = (new_eve_file.iloc[:,0]*1000).astype(int)\n",
    "    new_eve_file.iloc[0,2] = 0  #create one pseudo-event (that is going to be dropped later for some reason)\n",
    "    new_eve_file.iloc[:,0] = new_eve_file.iloc[:,0].astype(int)\n",
    "    new_eve_file.iloc[:,1] = new_eve_file.iloc[:,1].astype(str)\n",
    "    new_eve_file.iloc[:,2] = new_eve_file.iloc[:,2].astype(int)\n",
    "    new_eve_file.iloc[:,1] = int(\"0\")\n",
    "\n",
    "    name_of_events = np.unique(eve.iloc[:,0])\n",
    "    name_of_events = np.sort(name_of_events)\n",
    "    event_dict=dict()\n",
    "    event_dict['ignore_me']=0\n",
    "    for i in range(name_of_events.size):\n",
    "        key = (name_of_events[i])\n",
    "        val = i + 1\n",
    "        event_dict[key] = val\n",
    "    return new_eve_file, event_dict\n",
    "\n",
    "def raw_to_epoch(raw, rawfile=None, picks=[\"meg\", \"eeg\"]) -> mne.Epochs:\n",
    "    \"\"\"\n",
    "    Receives a raw file, finds the corresponding event-file\n",
    "    Returns an epoch-file\n",
    "    \"\"\"\n",
    "    eve_name = rawfile.split(\".fif\")[0] + \".csv\"\n",
    "    if not os.path.isfile(eve_name):\n",
    "        eve_name = rawfile.split(\".fif\")[0] + \".txt\"\n",
    "    if os.path.isfile(eve_name): # if fif-file matches event-file --> add events to fif-file\n",
    "        try:\n",
    "            print(f\"\\n\\nNow epoching events from {rawfile}\\n\\n\")\n",
    "            event_file, event_dict = transform_eventfile(eve_name)\n",
    "            print(f\"\\n\\nevent_file: {event_file}\")\n",
    "            print(f\"\\n\\nevent_dict: {event_dict}\")\n",
    "            epochs = mne.Epochs(raw, events=event_file,\n",
    "                                event_id=event_dict, \n",
    "                                tmin=-1.5, tmax=1, \n",
    "                                baseline=(-1.5,-0.7), \n",
    "                                on_missing = \"ignore\", \n",
    "                                picks=picks,\n",
    "                                reject=None,\n",
    "                                event_repeated=\"merge\",\n",
    "                                #reject_by_annotation=False,  # nothing is dropped, but some epochs are empty\n",
    "                                )\n",
    "            del(raw)\n",
    "            return epochs\n",
    "        except Exception as e:\n",
    "            print(f\"failed at returning an epochs object for: {rawfile}\\nbecause of {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### epoching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epo_filename = os.path.join(dfc.spikes, str(subject) + \"-epo.fif\")\n",
    "if os.path.isfile(epo_filename):\n",
    "    print(f\"Epoched file exists at: {epo_filename}, aborting.\")\n",
    "    epochs = mne.read_epochs(epo_filename)\n",
    "else:\n",
    "    epochs = raw_to_epoch(raw, rawfile=rawfile)\n",
    "    epochs.save(epo_filename, overwrite=True)\n",
    "    #else:\n",
    "    #    print(f\"Epoch file was not found, did you mark the spikes and save the file as {epo_filename} ?\")\n",
    "\n",
    "\n",
    "\n",
    "    ##################\n",
    "    ### FIX ME!!!! ###\n",
    "    ##################\n",
    "\n",
    "\n",
    "    #some epochs are empty (no data), although they shouldn't be.\n",
    "    # this breaks saving,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epochs[\"Single_Spike_3_re\"].plot()\n",
    "epochs.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.drop_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epo_filename = os.path.join(dfc.spikes, str(subject) + \"-epo.fif\")\n",
    "print(epo_filename)\n",
    "epochs.save(epo_filename, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ECG artifact correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_channel = \"ECG003\"\n",
    "n_grad: int = 1\n",
    "n_mag: int = 1\n",
    "n_eeg: int = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ecg_projs, _ = mne.preprocessing.compute_proj_ecg(raw, n_grad=n_grad, n_mag=n_mag, \n",
    "                                                      n_eeg=n_eeg, reject=None, n_jobs=n_jobs)\n",
    "    raw.add_proj(ecg_projs, remove_existing=False)\n",
    "    fig = mne.viz.plot_projs_topomap(ecg_projs, info=raw.info, show=True)\n",
    "    savename = os.path.join(dfc.fprep, \"ECG_projs_Topomap.png\")\n",
    "    fig.savefig(savename)\n",
    "except Exception as e:\n",
    "    print(f\"ECG - Atrifact correction failed --> {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## EOG artifact correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    eog_evoked = mne.preprocessing.create_eog_epochs(raw).average()\n",
    "    # eog_evoked.apply_baseline((None, None))\n",
    "    eog_projs, _ = mne.preprocessing.compute_proj_eog(\n",
    "        raw,\n",
    "        n_grad=n_grad,\n",
    "        n_mag=n_mag,\n",
    "        n_eeg=n_eeg,\n",
    "        n_jobs=n_jobs,\n",
    "        reject=None,\n",
    "    )\n",
    "    raw.add_proj(\n",
    "        eog_projs, remove_existing=False\n",
    "    )  # --> don't do this in the early stages - see documentation\n",
    "    figs = eog_evoked.plot_joint(show=True)\n",
    "    for idx, fig in enumerate(figs):\n",
    "        savename = os.path.join(\n",
    "            dfc.fprep, \"EOG Topomap_\" + str(idx) + \".png\"\n",
    "        )\n",
    "        fig.savefig(savename)\n",
    "except Exception as e:\n",
    "    print(f\"EOG - Atrifact correction failed --> {e}\")\n",
    "\n",
    "# store projs\n",
    "all_projs = raw.info[\"projs\"]\n",
    "savename = os.path.join(dfc.fprep, \"all_projs.pkl\")\n",
    "with open(savename, \"wb\") as s:\n",
    "    pickle.dump(all_projs, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## save raw file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#rawfile = \"/home/meg/Schreibtisch/new_patients/processed/sub-FT05042011_prepped.fif\"\n",
    "rawfile = rawfile.strip(\".fif\") + \"_artcorr.fif\"\n",
    "raw.save(rawfile, overwrite=True)\n",
    "raw = mne.io.read_raw(rawfile, preload=False)\n",
    "\n",
    "derivatives_root = os.path.join(bids_root, \"derivatives\")\n",
    "# meg\n",
    "bids_path = BIDSPath(\n",
    "    subject=ject,\n",
    "    session=\"resting\",\n",
    "    task=\"resting\",\n",
    "    root=derivatives_root,\n",
    "    processing=\"concat\")\n",
    "\n",
    "write_raw_bids(raw, bids_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Frequency spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_single_shell_model = True   # fall back to single shell head model, if nothing better is available\n",
    "freq_bands = dict(  # the frequency bands of interest for the analysis\n",
    "    delta=(1, 4), \n",
    "    theta=(4, 7), \n",
    "    alpha=(8, 12), \n",
    "    beta=(13, 29), \n",
    "    gamma=(30, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bem_sol = os.path.join(dfc.fsrc, subject + \"-3-layer-BEM-sol.fif\")\n",
    "if not os.path.isfile(bem_sol) and use_single_shell_model:\n",
    "    print(\"Working with a single shell head model\")\n",
    "    bem_sol = os.path.join(dfc.fsrc, subject + \"-single-shell-BEM-sol.fif\")\n",
    "\n",
    "fwd_name = os.path.join(dfc.fsrc, subject + \"-fwd.fif\")\n",
    "srcfilename = os.path.join(dfc.fsrc, subject + \"-\" + spacing + \"-src.fif\")\n",
    "filebase = str(subject) + \"_Freqs\"\n",
    "all_stcs_filename = filebase + \"-stc-psd-MNE.pkl\"\n",
    "all_stcs_filename = os.path.join(dfc.freq, all_stcs_filename)\n",
    "sensor_psd_filename = filebase + \"-sensor-psd-MNE.pkl\"\n",
    "sensor_psd_filename = os.path.join(dfc.freq, sensor_psd_filename)\n",
    "transfile = os.path.join(dfc.ftrans, subject + \"-trans.fif\")\n",
    "derivatives_root = os.path.join(bids_root, \"derivatives\")\n",
    "\n",
    "bids_path = BIDSPath(\n",
    "    subject=ject,\n",
    "    session=\"resting\",\n",
    "    task=\"resting\",\n",
    "    root=derivatives_root,\n",
    "    processing=\"concat\")\n",
    "\n",
    "if not os.path.isfile(all_stcs_filename) or not os.path.isfile(\n",
    "                                                sensor_psd_filename):\n",
    "    raw = read_raw_bids(bids_path, preload=True)\n",
    "    \n",
    "    if os.path.isfile(fwd_name):\n",
    "        fwd = mne.read_forward_solution(fwd_name)\n",
    "    else:\n",
    "        fwd = mne.make_forward_solution(\n",
    "            raw.info,\n",
    "            src=srcfilename,\n",
    "            bem=bem_sol,\n",
    "            trans=transfile,\n",
    "            meg=True,\n",
    "            eeg=False,\n",
    "            mindist=0.2,\n",
    "            ignore_ref=False,\n",
    "            n_jobs=n_jobs,\n",
    "            verbose=True,\n",
    "        )\n",
    "        mne.write_forward_solution(fwd_name, fwd)\n",
    "    noise_cov = mne.compute_raw_covariance(\n",
    "        raw, method=\"empirical\", n_jobs=n_jobs\n",
    "    )\n",
    "    inv = mne.minimum_norm.make_inverse_operator(\n",
    "        raw.info, forward=fwd, noise_cov=noise_cov, loose=\"auto\", depth=0.8\n",
    "    )\n",
    "    snr = 3.0\n",
    "    stc_psd, sensor_psd = mne.minimum_norm.compute_source_psd(\n",
    "        raw,\n",
    "        inv,\n",
    "        lambda2=lambda2,\n",
    "        method=\"MNE\",\n",
    "        fmin=1,\n",
    "        fmax=45,\n",
    "        n_fft=2048,\n",
    "        n_jobs=n_jobs,\n",
    "        return_sensor=True,\n",
    "        verbose=True,\n",
    "    )\n",
    "    pickle.dump(stc_psd, open(all_stcs_filename, \"wb\"))\n",
    "    pickle.dump(sensor_psd, open(sensor_psd_filename, \"wb\"))\n",
    "else:\n",
    "    stc_psd = pickle.load(open(all_stcs_filename, \"rb\"))\n",
    "    sensor_psd = pickle.load(open(sensor_psd_filename, \"rb\"))\n",
    "\n",
    "# Visualization\n",
    "topos = dict()\n",
    "stcs = dict()\n",
    "topo_norm = sensor_psd.data.sum(axis=1, keepdims=True)\n",
    "stc_norm = stc_psd.sum()\n",
    "for band, limits in freq_bands.items():  # normalize...\n",
    "    data = sensor_psd.copy().crop(*limits).data.sum(axis=1, keepdims=True)\n",
    "    topos[band] = mne.EvokedArray(100 * data / topo_norm, sensor_psd.info)\n",
    "    stcs[band] = 100 * stc_psd.copy().crop(*limits).sum() / stc_norm.data\n",
    "brain = dict()\n",
    "x_hemi_freq = dict()\n",
    "#mne.viz.set_3d_backend(\"pyvista\")\n",
    "for band in freq_bands.keys():\n",
    "# dorsal    \n",
    "    brain[band] = u.plot_freq_band_dors(\n",
    "        stcs[band],\n",
    "        band=band,\n",
    "        subject=subject,\n",
    "        subjects_dir=dfc.fanat,\n",
    "        filebase=filebase,\n",
    "    )\n",
    "    freqfilename3d = filebase + \"_\" + band + \"_freq_topomap_3d_dors.png\"\n",
    "    freqfilename3d = os.path.join(dfc.freq, freqfilename3d)\n",
    "    image = brain[band].save_image(freqfilename3d)\n",
    "# lateral    \n",
    "    brain_lh, brain_rh = u.plot_freq_band_lat(\n",
    "        stcs[band],\n",
    "        band=band,\n",
    "        subject=subject,\n",
    "        subjects_dir=dfc.fanat,\n",
    "        filebase=filebase,\n",
    "    )\n",
    "    freqfilename3d = filebase + \"_\" + band + \"_freq_topomap_3d_lat_lh.png\"\n",
    "    freqfilename3d = os.path.join(dfc.freq, freqfilename3d)\n",
    "    image = brain_lh.save_image(freqfilename3d)\n",
    "    freqfilename3d = filebase + \"_\" + band + \"_freq_topomap_3d_lat_rh.png\"\n",
    "    freqfilename3d = os.path.join(dfc.freq, freqfilename3d)\n",
    "    image = brain_rh.save_image(freqfilename3d)\n",
    "# medial    \n",
    "    brain_lh, brain_rh = u.plot_freq_band_med(\n",
    "        stcs[band],\n",
    "        band=band,\n",
    "        subject=subject,\n",
    "        subjects_dir=dfc.fanat,\n",
    "        filebase=filebase,\n",
    "    )\n",
    "    freqfilename3d = filebase + \"_\" + band + \"_freq_topomap_3d_med_lh.png\"\n",
    "    freqfilename3d = os.path.join(dfc.freq, freqfilename3d)\n",
    "    image = brain_lh.save_image(freqfilename3d)\n",
    "    freqfilename3d = filebase + \"_\" + band + \"_freq_topomap_3d_med_rh.png\"\n",
    "    freqfilename3d = os.path.join(dfc.freq, freqfilename3d)\n",
    "    image = brain_rh.save_image(freqfilename3d)\n",
    "    \n",
    "# Cross hemisphere comparison\n",
    "    # make sure fsaverage_sym exists in local subjects dir:\n",
    "    print(f\"Calculating cross hemisphere comparison for {band}.\")\n",
    "    target = os.path.join(dfc.fanat, \"fsaverage_sym\")\n",
    "    if not os.path.isdir(target):\n",
    "        # try to find it in $SUBJECTS_DIR and copy\n",
    "        os_subj_dir = os.environ.get(\"SUBJECTS_DIR\")\n",
    "        fs_avg_sym_dir = os.path.join(os_subj_dir, \"fsaverage_sym\")\n",
    "        u.recursive_overwrite(fs_avg_sym_dir, target)\n",
    "    if not os.path.isdir(target):\n",
    "        print(\"fsaverage_sym not found - aborting\")\n",
    "        raise Exception\n",
    "    mstc = stcs[band].copy()\n",
    "    mstc = mne.compute_source_morph(\n",
    "        mstc,\n",
    "        subject,\n",
    "        \"fsaverage_sym\",\n",
    "        smooth=5,\n",
    "        warn=False,\n",
    "        subjects_dir=dfc.fanat,\n",
    "    ).apply(mstc)\n",
    "    morph = mne.compute_source_morph(\n",
    "        mstc,\n",
    "        \"fsaverage_sym\",\n",
    "        \"fsaverage_sym\",\n",
    "        spacing=mstc.vertices,\n",
    "        warn=False,\n",
    "        subjects_dir=dfc.fanat,\n",
    "        xhemi=True,\n",
    "        verbose=\"error\",\n",
    "    )\n",
    "    stc_xhemi = morph.apply(mstc)\n",
    "    diff = mstc - stc_xhemi\n",
    "    title = \"blue = RH; \" + subject + \" -Freq-x_hemi- \" + band\n",
    "    x_hemi_freq[band] = diff.plot(\n",
    "        hemi=\"lh\",\n",
    "        subjects_dir=dfc.fanat,\n",
    "        size=(1200, 800),\n",
    "        time_label=title,\n",
    "        add_data_kwargs=dict(time_label_size=10),\n",
    "    )\n",
    "    freqfilename3d = filebase + \"_x_hemi_\" + band + \".png\"\n",
    "    freqfilename3d = os.path.join(dfc.freq, freqfilename3d)\n",
    "    image = x_hemi_freq[band].save_image(freqfilename3d)\n",
    "pyvista.close_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Source localization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_loc_methods = [\"dSPM\", \"eLORETA\", \"ECD\"] # [\"dSPM\", \"eLORETA\", \"ECD\"] --> expects a list\n",
    "snr = 3\n",
    "lambda2 = 1.0 / snr ** 2\n",
    "peaks_tmin, peaks_tmax = -0.025, 0.\n",
    "peaks_mode = \"abs\"  # How to deal with the sign of the data:  \"pos\", \"neg\", or \"abs\"\n",
    "peaks_nr_of_points = 5\n",
    "\n",
    "dip_times = {\n",
    "    \"min20ms\": (-0.025,-0.020),  # Time windows in Miliseconds for Equivalent current dipole fit\n",
    "    \"min15ms\": (-0.019, -0.015),\n",
    "    \"min10ms\": (-0.014, -0.010),\n",
    "    \"min5ms\": (-0.009, -0.005),\n",
    "    \"peak\": (-0.004, 0.000),\n",
    "}\n",
    "\n",
    "use_single_shell_model = True  # if 3-layer-BEM fails for some reason\n",
    "picks=[\"meg\", \"eeg\"]\n",
    "\n",
    "noise_cov_file = os.path.join(dfc.spikes, \"Spikes_noise_covariance.pkl\")\n",
    "srcfilename = os.path.join(dfc.fsrc, subject + \"-\" + spacing + \"-src.fif\")\n",
    "epo_filename = os.path.join(dfc.spikes, str(subject) + \"-epo.fif\")\n",
    "ject = subject.strip(\"sub-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### create epoch file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_epochs = mne.read_epochs(epo_filename)\n",
    "concat_epochs.event_id.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# noise covariance\n",
    "if not os.path.isfile(noise_cov_file):\n",
    "    noise_cov = mne.compute_covariance(\n",
    "        concat_epochs, tmax=-1.0, method=\"auto\", n_jobs=n_jobs, rank=\"full\"\n",
    "    )\n",
    "    pickle.dump(noise_cov, open(noise_cov_file, \"wb\"))\n",
    "else:\n",
    "    with open(noise_cov_file, \"rb\") as f:\n",
    "        noise_cov = pickle.load(f)\n",
    "        \n",
    "for event in concat_epochs.event_id.keys():\n",
    "    eventname = str(event)\n",
    "    if (\n",
    "        eventname == \"ignore_me\"\n",
    "        or eventname == \"AAA\"\n",
    "        or eventname.startswith(\".\")\n",
    "    ):\n",
    "        print(f\"Omitting event {event}\")\n",
    "    else:\n",
    "        try:\n",
    "            print(f\"Now localizing event: {event}\")\n",
    "            e = (\n",
    "                concat_epochs[eventname]\n",
    "                .load_data()\n",
    "                .crop(tmin=-0.5, tmax=0.5)\n",
    "                .average()\n",
    "            )\n",
    "            e_folder = os.path.join(dfc.spikes, eventname)\n",
    "            evoked_filename = os.path.join(e_folder, ject + \"_\" + eventname + \"-ave.fif\")\n",
    "            cp_folder = os.path.join(dfc.spikes, eventname, \"custom_pics\")\n",
    "            cts_folder = os.path.join(dfc.spikes, eventname, \"custom_time_series\")\n",
    "            gp_folder = os.path.join(dfc.spikes, eventname, \"generic_pics\")\n",
    "            folders = [e_folder, cp_folder, cts_folder, gp_folder]\n",
    "            if not os.path.isdir(e_folder):\n",
    "                for f in folders:\n",
    "                    os.mkdir(f)\n",
    "            e.save(evoked_filename)\n",
    "            src = mne.read_source_spaces(srcfilename)\n",
    "            bem_sol = os.path.join(dfc.fsrc, subject + \"-3-layer-BEM-sol.fif\")\n",
    "            if not os.path.isfile(bem_sol) and use_single_shell_model:\n",
    "                bem_sol = os.path.join(dfc.fsrc, subject + \"-single-shell-BEM-sol.fif\")\n",
    "\n",
    "            fwd_name = os.path.join(dfc.fsrc, subject + \"-fwd.fif\")\n",
    "            if os.path.isfile(fwd_name):\n",
    "                fwd = mne.read_forward_solution(fwd_name)\n",
    "            else:\n",
    "                fwd = mne.make_forward_solution(\n",
    "                    e.info,\n",
    "                    src=src,\n",
    "                    bem=bem_sol,\n",
    "                    trans=transfile,\n",
    "                    meg=True,\n",
    "                    eeg=False,\n",
    "                    mindist=0.2,\n",
    "                    ignore_ref=False,\n",
    "                    n_jobs=n_jobs,\n",
    "                    verbose=True,\n",
    "                )\n",
    "            # inv for cortical surface\n",
    "            inv = mne.minimum_norm.make_inverse_operator(\n",
    "                e.info, forward=fwd, noise_cov=noise_cov, loose=0.2, depth=0.8\n",
    "            )\n",
    "            # inv with volume source space\n",
    "            vol_srcfilename = os.path.join(dfc.fsrc, subject + \"-vol-src.fif\")\n",
    "            src_vol = mne.read_source_spaces(vol_srcfilename)\n",
    "            fwd_vol = mne.make_forward_solution(\n",
    "                e.info,\n",
    "                src=src_vol,\n",
    "                bem=bem_sol,\n",
    "                trans=transfile,\n",
    "                meg=True,\n",
    "                eeg=False,\n",
    "                mindist=0.2,\n",
    "                ignore_ref=False,\n",
    "                n_jobs=n_jobs,\n",
    "                verbose=True,\n",
    "            )\n",
    "            inv_vol = mne.minimum_norm.make_inverse_operator(\n",
    "                e.info, forward=fwd_vol, noise_cov=noise_cov, loose=1, depth=0.8\n",
    "            )\n",
    "            for m in source_loc_methods:\n",
    "                stc_name = \"stc_\" + m\n",
    "                if m == \"dSPM\":\n",
    "                    # calculate vector solution in volume source space\n",
    "                    try:\n",
    "                        print(\"Now calculating dSPM vector solution...\")\n",
    "                        stc_name = mne.minimum_norm.apply_inverse(\n",
    "                            e,\n",
    "                            inv_vol,\n",
    "                            lambda2,\n",
    "                            method=\"dSPM\",\n",
    "                            pick_ori=\"vector\",\n",
    "                        )\n",
    "                        surfer_kwargs = dict(\n",
    "                            subjects_dir=dfc.fanat,\n",
    "                            src=inv_vol[\"src\"],\n",
    "                            clim=dict(kind=\"percent\", lims=[90, 96, 99.85]),\n",
    "                            colorbar=True,\n",
    "                            initial_time=0,\n",
    "                            #time_unit=\"ms\",\n",
    "                            #size=(1000, 800),\n",
    "                            #smoothing_steps=10,\n",
    "                        )\n",
    "                        brain = stc_name.plot(**surfer_kwargs)\n",
    "                        #label = str(ject + \" - \" + eventname + \" - Vector solution\")\n",
    "                        #brain.add_text(0.1, 0.9, label, \"title\", font_size=10)\n",
    "                        img_f_name = (\"img_stc_\" + ject + \"_\" + eventname + \"_\"+ m + \".png\")\n",
    "                        img_f_name = os.path.join(gp_folder, img_f_name)\n",
    "                        #brain.save_image(img_f_name)\n",
    "                        stc_f_name = (\n",
    "                            \"stc_\" + ject + \"_\" + eventname + \"_\" + m + \".h5\"\n",
    "                        )\n",
    "                        stc_f_name = os.path.join(e_folder, stc_f_name)\n",
    "                        stc_name = stc_name.crop(tmin=stc_tmin, tmax=stc_tmax)\n",
    "                        print(\"Saving dSPM vector solution.\")\n",
    "                        stc_name.save(stc_f_name)\n",
    "                    except Exception as ex:\n",
    "                        print(f\"dSPM failed --> {ex}\")\n",
    "                else:\n",
    "                    stc_name = mne.minimum_norm.apply_inverse(\n",
    "                        e, inv, lambda2, method=m, pick_ori=None\n",
    "                    )\n",
    "                    surfer_kwargs = dict(\n",
    "                        hemi=\"split\",\n",
    "                        subjects_dir=dfc.fanat,\n",
    "                        clim=dict(kind=\"percent\", lims=[90, 96, 99.85]),\n",
    "                        views=[\"lat\", \"med\"],\n",
    "                        colorbar=True,\n",
    "                        initial_time=0,\n",
    "                        time_unit=\"ms\",\n",
    "                        size=(1000, 800),\n",
    "                        smoothing_steps=10,\n",
    "                    )\n",
    "                    brain = stc_name.plot(**surfer_kwargs)\n",
    "                    label = str(ject + \" - \" + eventname + \" - \" + m)\n",
    "                    brain.add_text(0.1, 0.9, label, \"title\", font_size=10)\n",
    "                    img_f_name = (\n",
    "                        \"img_stc_\" + ject + \"_\" + eventname + \"_\" + m + \".png\"\n",
    "                    )\n",
    "                    img_f_name = os.path.join(gp_folder, img_f_name)\n",
    "                    brain.save_image(img_f_name)\n",
    "                    stc_f_name = \"stc_\" + ject + \"_\" + eventname + \"_\" + m\n",
    "                    stc_f_name = os.path.join(e_folder, stc_f_name)\n",
    "                    stc_name = stc_name.crop(tmin=stc_tmin, tmax=stc_tmax)\n",
    "                    print(\"Saving eLORETA.\")\n",
    "                    stc_name.save(stc_f_name)\n",
    "                    if m == \"eLORETA\":\n",
    "                        try:\n",
    "                            print(\n",
    "                                \"Now calculating eLORETA with peaks...\"\n",
    "                            )\n",
    "                            rh_peaks = u.get_peak_points(\n",
    "                                stc_name,\n",
    "                                hemi=\"rh\",\n",
    "                                tmin=peaks_tmin,\n",
    "                                tmax=peaks_tmax,\n",
    "                                nr_points=peaks_nr_of_points,\n",
    "                                mode=peaks_mode,\n",
    "                            )\n",
    "                            lh_peaks = u.get_peak_points(\n",
    "                                stc_name,\n",
    "                                hemi=\"lh\",\n",
    "                                tmin=peaks_tmin,\n",
    "                                tmax=peaks_tmax,\n",
    "                                nr_points=peaks_nr_of_points,\n",
    "                                mode=peaks_mode,\n",
    "                            )\n",
    "                            label = str(\n",
    "                                ject\n",
    "                                + \" - \"\n",
    "                                + eventname\n",
    "                                + \" - \"\n",
    "                                + m\n",
    "                                + \" - max. activation points\"\n",
    "                            )\n",
    "                            brain.add_text(\n",
    "                                0.1, 0.9, label, font_size=10\n",
    "                            )  # , 'title'\n",
    "                            for p in rh_peaks:\n",
    "                                brain.add_foci(\n",
    "                                    p,\n",
    "                                    color=\"green\",\n",
    "                                    coords_as_verts=True,\n",
    "                                    hemi=\"rh\",\n",
    "                                    scale_factor=0.6,\n",
    "                                    alpha=0.9,\n",
    "                                )\n",
    "                            for p in lh_peaks:\n",
    "                                brain.add_foci(\n",
    "                                    p,\n",
    "                                    color=\"green\",\n",
    "                                    coords_as_verts=True,\n",
    "                                    hemi=\"lh\",\n",
    "                                    scale_factor=0.6,\n",
    "                                    alpha=0.9,\n",
    "                                )\n",
    "                            stc_f_name = (\n",
    "                                \"stc_\"\n",
    "                                + ject\n",
    "                                + \"_\"\n",
    "                                + eventname\n",
    "                                + \"_\"\n",
    "                                + m\n",
    "                                + \"_with_peaks-ave\"\n",
    "                            )\n",
    "                            stc_f_name = os.path.join(e_folder, stc_f_name)\n",
    "                            stc_name.save(stc_f_name)\n",
    "                            img_f_name = (\n",
    "                                \"img_stc_\"\n",
    "                                + ject\n",
    "                                + \"_\"\n",
    "                                + eventname\n",
    "                                + \"_\"\n",
    "                                + m\n",
    "                                + \"_with_peaks.png\"\n",
    "                            )\n",
    "                            img_f_name = os.path.join(gp_folder, img_f_name)\n",
    "                            brain.save_image(img_f_name)\n",
    "                        except Exception as ex:\n",
    "                            print(f\"eLORETA with peaks failed --> {ex}\")\n",
    "            # Dipoles\n",
    "            if \"ECD\" in source_loc_methods:\n",
    "                print(\"Now calculating ECD.\")\n",
    "                try:\n",
    "                    for start, stop in dip_times.values():\n",
    "                        dip_epoch = e.copy().crop(start, stop).pick(\"meg\")\n",
    "                        ecd = mne.fit_dipole(\n",
    "                            dip_epoch, noise_cov, bem_sol, trans=transfile\n",
    "                        )[0]\n",
    "                        best_idx = np.argmax(ecd.gof)\n",
    "                        best_time = ecd.times[best_idx]\n",
    "                        trans = mne.read_trans(transfile)\n",
    "                        mri_pos = mne.head_to_mri(\n",
    "                            ecd.pos,\n",
    "                            mri_head_t=trans,\n",
    "                            subject=subject,\n",
    "                            subjects_dir=dfc.fanat,\n",
    "                        )\n",
    "                        t1_file_name = os.path.join(\n",
    "                            dfc.fanat, subject, \"mri\", \"T1.mgz\"\n",
    "                        )\n",
    "                        stoptime = str(abs(int(stop * int(e.info[\"sfreq\"]))))\n",
    "                        if stoptime == \"5\":\n",
    "                            stoptime = \"05\"\n",
    "                        title = str(\n",
    "                            eventname + \" - ECD @ minus \" + stoptime + \" ms\"\n",
    "                        )\n",
    "                        t1_fig = plot_anat(\n",
    "                            t1_file_name, cut_coords=mri_pos[0], title=title\n",
    "                        )\n",
    "                        t1_f_name_pic = (\n",
    "                            \"img_ecd_\"\n",
    "                            + eventname\n",
    "                            + \"_\"\n",
    "                            + \"_Dipol_\"\n",
    "                            + stoptime\n",
    "                            + \".png\"\n",
    "                        )\n",
    "                        t1_f_name_pic = os.path.join(\n",
    "                            e_folder, \"generic_pics\", t1_f_name_pic\n",
    "                        )\n",
    "                        t1_fig.savefig(t1_f_name_pic)\n",
    "                        fig_3d = ecd.plot_locations(\n",
    "                            trans, subject, dfc.fanat, mode=\"orthoview\"\n",
    "                        )\n",
    "                        fig_3d_pic = (\n",
    "                            \"img_3d_ecd_\"\n",
    "                            + eventname\n",
    "                            + \"_\"\n",
    "                            + \"_Dipol_\"\n",
    "                            + stoptime\n",
    "                            + \".png\"\n",
    "                        )\n",
    "                        fig_3d_pic = os.path.join(\n",
    "                            e_folder, \"generic_pics\", fig_3d_pic\n",
    "                        )\n",
    "                        fig_3d.savefig(fig_3d_pic)\n",
    "                        plt.close(\"all\")\n",
    "                except Exception as ex:\n",
    "                    print(f\"ECD calculation failed --> {ex}\")\n",
    "        except Exception as ex:\n",
    "            print(f\"Source localization failed because of:\\n {ex}\")\n",
    "else:\n",
    "    print(\"Source localization skipped, as no -epo file was found.\")\n",
    "pyvista.close_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import Reporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivatives_root = os.path.join(bids_root, \"derivatives\")\n",
    "reporter = Reporter.EpilepsyReportBuilder(\n",
    "            derivatives_root=derivatives_root,\n",
    "            subject=subject,\n",
    "            extras_dir=extras_directory)\n",
    "reporter.create_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfile = \"/run/media/meg/DATA/MEG/BIDS_clinic/derivatives/sub-VA09051993/spikes/Gr_1_li/VA09051993_Gr_1_li-ave.fif\"\n",
    "epo = mne.read_evokeds(rawfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epo[0].plot_sensors(kind=\"topomap\", ch_type=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6-final"
  },
  "vscode": {
   "interpreter": {
    "hash": "efac0460eee90c397688410beb991c05e0e16af2b500d70dd2ead6bd85f721dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}