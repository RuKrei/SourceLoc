{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source localization pipeline - Stage1\n",
    "- freesurfer\n",
    "- .fif-File preparations\n",
    " \n",
    " \n",
    "\n",
    "\n",
    "#### Author\n",
    "Rudi Kreidenhuber <Rudi.Kreidenhuber@gmail.com>\n",
    "#### License\n",
    "BSD (3-clause)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from src import SubjectDropDowner\n",
    "import os\n",
    "import glob\n",
    "import mne\n",
    "\n",
    "input_dir = \"..\\\\..\\\\MEG_playground\"\n",
    "\n",
    "def get_subject_list(input_dir = input_dir) -> list:\n",
    "    analist = glob.glob(os.path.join(input_dir, \"*\"))\n",
    "    analist = [os.path.basename(f) for f in analist if os.path.isdir(f)]\n",
    "    fiflist = [os.path.basename(f) for f in glob.glob(os.path.join(input_dir, \"*trans_tsss.fif\"))]\n",
    "    fiflist = [f.split(\"_\")[0] for f in fiflist]\n",
    "    subjectlist = set(fiflist + analist)\n",
    "    subjectlist = sorted([f for f in subjectlist])\n",
    "    return subjectlist\n",
    "\n",
    "subjectlist = get_subject_list()\n",
    "\n",
    "dl = SubjectDropDowner.SubjectDropDowner(subjectlist)\n",
    "drop_menu = dl.create_subject_dropdown_widget()\n",
    "print(f\"\\n\\nThe following patients/ subjects are available:\")\n",
    "drop_menu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .fif - File preprocessing\n",
    "- Files are being filtered, downsampled and concatenated\n",
    "- Files without head transposition and artifact correction via tsss are omitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = dl.get_subject_dropdown().value\n",
    "\n",
    "if not subject.startswith(\"sub-\"):\n",
    "    ject = subject\n",
    "    subject = \"sub-\" + subject\n",
    "else:\n",
    "    subject = subject\n",
    "    ject = subject.replace(\"sub-\", \"\")\n",
    "\n",
    "if not os.path.isdir(os.path.join(input_dir, \"processed\")):\n",
    "    os.mkdir(os.path.join(input_dir, \"processed\"))\n",
    "\n",
    "output_dir = os.path.join(input_dir, \"processed\")\n",
    "target_file = os.path.join(output_dir, str(subject + \"_prepped.fif\"))\n",
    "\n",
    "# Make sure we haven't already processed this subject\n",
    "if os.path.isfile(target_file):\n",
    "    print(f\"\\n\\nThe file {target_file} already exists, aborting.\\n\\n\")\n",
    "    raise(FileExistsError)\n",
    "\n",
    "# Configuration \n",
    "# Filter and resample\n",
    "l_freq: float = 0.1         # lower pass-band edge\n",
    "h_freq: float = 50.         # higher pass-band edge\n",
    "fir_design: str = \"firwin\"  # Filter design method\n",
    "s_freq: int = 300           # target sampling frequency\n",
    "# ECG artifact correction\n",
    "ecg_channel = \"ECG003\"\n",
    "n_grad: int =1\n",
    "n_mag: int = 1\n",
    "n_eeg: int = 1\n",
    "\n",
    "\n",
    "# Get all .fif files of the subject\n",
    "raws = glob.glob(input_dir + \"*_trans_tsss.fif\")\n",
    "raws = [f for f in raws if ject in f]\n",
    "print(f\"The following raw files were found for preprocessing:\\n{raws}\")\n",
    "\"\"\"\n",
    "prep_raws = []\n",
    "for r in raws:\n",
    "    raw = mne.io.read_raw(r)\n",
    "    # filter\n",
    "    raw.load_data()\n",
    "    raw = raw.filter(l_freq, h_freq, fir_design=fir_design)\n",
    "    # downsample\n",
    "    if not raw.info[\"sfreq\"] == s_freq:\n",
    "        raw = raw.resample(s_freq)\n",
    "    prep_raws.append(raw)\n",
    "    del raw\n",
    "\"\"\"\n",
    "# concatenate\n",
    "try:\n",
    "    raw = mne.concatenate_raws(prep_raws)\n",
    "    raw.save(target_file, overwrite=False)\n",
    "except Exception as e:\n",
    "    print(f\"\\n\\nSomething went wrong, when trying to concatenate the raw files:\\n\\nError: {e}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freesurfer and hippocampal segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dicom_file(subject) -> str:\n",
    "    if not os.path.isdir(os.path.join(input_dir, subject)):\n",
    "        print(f\"No anatomical data found for {subject}, aborting\\n\\n\")\n",
    "        raise(FileNotFoundError)\n",
    "    else:\n",
    "        dicom_path = os.path.join(input_dir, subject, \"1*\", \"100*\", \"1*\", \"*\")\n",
    "        dicom = str(glob.glob(dicom_path, recursive=True)[0])\n",
    "        dicom = os.path.abspath(dicom)\n",
    "        return dicom\n",
    "\n",
    "def path_to_wsl(file) -> str:\n",
    "    file = file.replace(\"\\\\\", \"/\")\n",
    "    return file.replace(\"c:\", \"/mnt/c\")\n",
    "\n",
    "def get_dicom_path(subject) -> str:\n",
    "    dicom = get_dicom_file(subject)\n",
    "    dicom = path_to_wsl(dicom)\n",
    "    return dicom\n",
    "\n",
    "def get_recon_all_command(ject) -> str:\n",
    "    dicom = get_dicom_path(ject)\n",
    "    subject = \"sub-\" + ject\n",
    "    command = f\"recon-all -s {subject} -i {dicom} -all && segmentHA_T1.sh {subject}\"\n",
    "    return command\n",
    "\n",
    "command = get_recon_all_command(ject)\n",
    "\n",
    "print(f\"\\n\\nExecute the following command in the WSL shell:\\n \\\n",
    "      (This will take hours...)\\n\\n{command}\\n\\n\")\n",
    "\n",
    "print(f\"Meanwhile use brainstorm3 to mark and group spikes on the \\\n",
    "following file:\\n\\n {os.path.abspath(target_file)}\\n\\n\")\n",
    "\n",
    "event_file_name = target_file.split(\".fif\")[0] + \"_Events.fif\"\n",
    "print(f\"Save the eventfile in the same directory as the raw file as: {os.path.basename(event_file_name)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "efac0460eee90c397688410beb991c05e0e16af2b500d70dd2ead6bd85f721dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
